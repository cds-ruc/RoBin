{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: alex, smo_counter: 50, counter: 60, ratio: 0.8333333333333334\n",
      "index: lipp, smo_counter: 49, counter: 60, ratio: 0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "# smo\n",
    "import pandas as pd\n",
    "\n",
    "bulkload_sizes = [0, 1000000, 2000000, 5000000, 10000000, 20000000, 50000000, 100000000]\n",
    "sizes2ratios = {\n",
    "    0: \"0.0\",\n",
    "    1000000: \"0.005\",\n",
    "    2000000: \"0.01\",\n",
    "    5000000: \"0.025\",\n",
    "    10000000: \"0.05\",\n",
    "    20000000: \"0.1\",\n",
    "    50000000: \"0.25\",\n",
    "    100000000: \"0.5\",\n",
    "}\n",
    "datasets = [\"linear\", \"covid\", \"fb-1\", \"osm\"]\n",
    "\n",
    "df = pd.read_csv(\"../data/AIO_trimed.csv\")\n",
    "df = df[(df[\"read_ratio\"] != 0)]\n",
    "df['key_path'] = df['key_path'].apply(lambda x: x.replace('fb', 'fb-1'))\n",
    "df_grouped = df.groupby(['index_type', 'key_path', 'test_suite', 'init_table_size'])['throughput'].mean().reset_index()\n",
    "\n",
    "result = {}\n",
    "\n",
    "for index in [\"alex\", \"lipp\"]:\n",
    "    smo_counter = 0\n",
    "    counter = 0\n",
    "    for case1 in [21, 41]:\n",
    "        for dataset in datasets:\n",
    "            for bulkload_size in bulkload_sizes:\n",
    "                    if case1 == 41 and bulkload_size == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    counter += 1\n",
    "\n",
    "                    if case1 == 21:\n",
    "                        case2 = 22\n",
    "                    else:\n",
    "                        case2 = 42\n",
    "                    \n",
    "                    # get case throughput\n",
    "                    d1 = df_grouped[(df_grouped[\"key_path\"] == f\"datasets/{dataset}\") & (df_grouped[\"init_table_size\"] == bulkload_size) & (df_grouped[\"test_suite\"] == case1) & (df_grouped[\"index_type\"] == index)][\"throughput\"].values\n",
    "                    d2 = df_grouped[(df_grouped[\"key_path\"] == f\"datasets/{dataset}\") & (df_grouped[\"init_table_size\"] == bulkload_size) & (df_grouped[\"test_suite\"] == case2) & (df_grouped[\"index_type\"] == index)][\"throughput\"].values\n",
    "                    f1 = f\"../log/root_smo_profiling/{dataset}/{case1}/{sizes2ratios[bulkload_size]}/{index}_insert_smo_stats.log\"\n",
    "                    f2 = f\"../log/root_smo_profiling/{dataset}/{case2}/{sizes2ratios[bulkload_size]}/{index}_insert_smo_stats.log\"\n",
    "                    p1 = pd.read_csv(f1)\n",
    "                    p2 = pd.read_csv(f2)\n",
    "                    smo_cnt1 = p1[\"count\"].sum()\n",
    "                    smo_cnt2 = p2[\"count\"].sum()\n",
    "                    if (smo_cnt1 > smo_cnt2 and d1[0] < d2[0]) or (smo_cnt1 < smo_cnt2 and d1[0] > d2[0]):\n",
    "                        smo_counter += 1\n",
    "                        # print(f\"index: {index}, {case1} vs. {case2}, [{smo_cnt1} vs. {smo_cnt2}]. dataset:{dataset}, bulkload_size: {bulkload_size}, {d1}/{d2}={d1/d2}\")\n",
    "    result[index] = (smo_counter, counter)\n",
    "\n",
    "# print(f\"smo_counter: {smo_counter}, counter: {counter}, ratio: {smo_counter/counter}\")\n",
    "for index in result:\n",
    "    print(f\"index: {index}, smo_counter: {result[index][0]}, counter: {result[index][1]}, ratio: {result[index][0]/result[index][1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
