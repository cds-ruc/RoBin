{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "learned_indexes = ['alex', 'lipp', 'dili', 'dytis']\n",
    "traditional_indexes = ['art', 'btree']\n",
    "\n",
    "df = pd.read_csv('./single_thread_thp.csv')\n",
    "\n",
    "# trim read_ratio = 0\n",
    "df = df[df['read_ratio'] != 0]\n",
    "\n",
    "grouped = df.groupby(['index_type', 'key_path', 'test_suite', 'init_table_size'])['throughput'].mean().reset_index()\n",
    "learned_dfs = {index: grouped[grouped['index_type'] == index] for index in learned_indexes}\n",
    "traditional_dfs = {index: grouped[grouped['index_type'] == index] for index in traditional_indexes}\n",
    "\n",
    "# Counting the number of cases where the throughput of learned indexes is worse and better than traditional indexes\n",
    "worse_cases_counts = {}\n",
    "better_cases_counts = {}\n",
    "for learned_index, learned_df in learned_dfs.items():\n",
    "    worse_cases_counts[learned_index] = {}\n",
    "    better_cases_counts[learned_index] = {}\n",
    "    for traditional_index, traditional_df in traditional_dfs.items():\n",
    "        # Merging the DataFrames\n",
    "        merged_df = pd.merge(learned_df, traditional_df, on=['key_path', 'test_suite', 'init_table_size'], suffixes=(f'_{learned_index}', f'_{traditional_index}'))\n",
    "        # Counting the worse and better cases\n",
    "        worse_cases_count = (merged_df[f'throughput_{learned_index}'] < merged_df[f'throughput_{traditional_index}']).sum()\n",
    "        better_cases_count = (merged_df[f'throughput_{learned_index}'] >= merged_df[f'throughput_{traditional_index}']).sum()\n",
    "        worse_cases_counts[learned_index][traditional_index] = worse_cases_count\n",
    "        better_cases_counts[learned_index][traditional_index] = better_cases_count\n",
    "\n",
    "worse_cases_df = pd.DataFrame(worse_cases_counts)\n",
    "worse_cases_df = worse_cases_df.T\n",
    "print(\"learned indexes worse than traditional indexes cases:\")\n",
    "print(worse_cases_df)\n",
    "\n",
    "better_cases_df = pd.DataFrame(better_cases_counts)\n",
    "better_cases_df = better_cases_df.T\n",
    "print(\"learned indexes better than traditional indexes cases:\")\n",
    "print(better_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of cases where the throughput of learned indexes is worse than traditional indexes for each dataset\n",
    "worse_cases_by_key_path = {}\n",
    "for key_path in grouped['key_path'].unique():\n",
    "    worse_cases_by_key_path[key_path] = {}\n",
    "    \n",
    "    # Filtering data for the current key_path\n",
    "    for learned_index, learned_df in learned_dfs.items():\n",
    "        worse_cases_by_key_path[key_path][learned_index] = {}\n",
    "        learned_key_path_df = learned_df[learned_df['key_path'] == key_path]\n",
    "        \n",
    "        for traditional_index, traditional_df in traditional_dfs.items():\n",
    "            traditional_key_path_df = traditional_df[traditional_df['key_path'] == key_path]\n",
    "            \n",
    "            # Merging the DataFrames for the current key_path\n",
    "            merged_df = pd.merge(\n",
    "                learned_key_path_df,\n",
    "                traditional_key_path_df,\n",
    "                on=['key_path', 'test_suite', 'init_table_size'],\n",
    "                suffixes=(f'_{learned_index}', f'_{traditional_index}')\n",
    "            )\n",
    "            \n",
    "            # Counting the worse cases\n",
    "            worse_cases_count = (merged_df[f'throughput_{learned_index}'] < merged_df[f'throughput_{traditional_index}']).sum()\n",
    "            worse_cases_by_key_path[key_path][learned_index][traditional_index] = worse_cases_count\n",
    "\n",
    "worse_cases_by_key_path_df = pd.DataFrame(worse_cases_by_key_path)\n",
    "print(\"learned indexes worse than traditional indexes cases on each dataset:\")\n",
    "print(worse_cases_by_key_path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art = grouped[grouped['index_type'] == 'art']\n",
    "art_worst_thpt_dict = {}\n",
    "art_best_thpt_dict = {}\n",
    "for i, row in df_art.iterrows():\n",
    "    if row['key_path'] not in art_worst_thpt_dict:\n",
    "        art_worst_thpt_dict[row['key_path']] = 1e9\n",
    "    if row['key_path'] not in art_best_thpt_dict:\n",
    "        art_best_thpt_dict[row['key_path']] = 0\n",
    "    art_worst_thpt_dict[row['key_path']] = min(art_worst_thpt_dict[row['key_path']], row['throughput'])\n",
    "    art_best_thpt_dict[row['key_path']] = max(art_best_thpt_dict[row['key_path']], row['throughput'])\n",
    "# print(\"art worst:\")\n",
    "# print(art_worst_thpt_dict)\n",
    "# print(\"art best:\")\n",
    "# print(art_best_thpt_dict)\n",
    "# print(\"====================================\")\n",
    "\n",
    "df_alex = grouped[grouped['index_type'] == 'alex']\n",
    "alex_worst_thpt_dict = {}\n",
    "alex_best_thpt_dict = {}\n",
    "for i, row in df_alex.iterrows():\n",
    "    if row['key_path'] not in alex_worst_thpt_dict:\n",
    "        alex_worst_thpt_dict[row['key_path']] = 1e9\n",
    "    if row['key_path'] not in alex_best_thpt_dict:\n",
    "        alex_best_thpt_dict[row['key_path']] = 0\n",
    "    alex_worst_thpt_dict[row['key_path']] = min(alex_worst_thpt_dict[row['key_path']], row['throughput'])\n",
    "    alex_best_thpt_dict[row['key_path']] = max(alex_best_thpt_dict[row['key_path']], row['throughput'])\n",
    "# print(\"alex worst:\")\n",
    "# print(alex_worst_thpt_dict)\n",
    "# print(\"alex best:\")\n",
    "# print(alex_best_thpt_dict)\n",
    "# print(\"====================================\")\n",
    "\n",
    "df_lipp = grouped[grouped['index_type'] == 'lipp']\n",
    "lipp_worst_thpt_dict = {}\n",
    "lipp_best_thpt_dict = {}\n",
    "for i, row in df_lipp.iterrows():\n",
    "    if row['key_path'] not in lipp_worst_thpt_dict:\n",
    "        lipp_worst_thpt_dict[row['key_path']] = 1e9\n",
    "    if row['key_path'] not in lipp_best_thpt_dict:\n",
    "        lipp_best_thpt_dict[row['key_path']] = 0\n",
    "    lipp_worst_thpt_dict[row['key_path']] = min(lipp_worst_thpt_dict[row['key_path']], row['throughput'])\n",
    "    lipp_best_thpt_dict[row['key_path']] = max(lipp_best_thpt_dict[row['key_path']], row['throughput'])\n",
    "# print(\"lipp worst:\")\n",
    "# print(lipp_worst_thpt_dict)\n",
    "# print(\"lipp best:\")\n",
    "# print(lipp_best_thpt_dict)\n",
    "# print(\"====================================\")\n",
    "\n",
    "for key_path in art_worst_thpt_dict:\n",
    "    print(f\"key_path: {key_path}\")\n",
    "    print(f\"alex worst: {(art_worst_thpt_dict[key_path] - alex_worst_thpt_dict[key_path]) / art_worst_thpt_dict[key_path]}\")\n",
    "    print(f\"lipp worst: {(art_worst_thpt_dict[key_path] - lipp_worst_thpt_dict[key_path]) / art_worst_thpt_dict[key_path]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
